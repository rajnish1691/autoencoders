{"cells":[{"cell_type":"markdown","metadata":{"id":"ZJj8fj8KziJ4"},"source":["#### Imagenet100 Evaluation"]},{"cell_type":"code","source":["# Connect Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd /content/gdrive/MyDrive/Colab Notebooks/Colab Notebooks/autoencoders\n","\n","%pwd"],"metadata":{"id":"Xz0FNqTjKgCg","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1765781236914,"user_tz":360,"elapsed":18739,"user":{"displayName":"Swati Shahi","userId":"11305998299635410874"}},"outputId":"5f29d970-5158-4cfd-e9e1-c9bef60dc6d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","/content/gdrive/.shortcut-targets-by-id/1UMow24kXYpDLYgShcir7-CB3ZYQsgEih/Colab Notebooks/autoencoders\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/gdrive/.shortcut-targets-by-id/1UMow24kXYpDLYgShcir7-CB3ZYQsgEih/Colab Notebooks/autoencoders'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["# Encoded test prediction\n","import numpy as np\n","from pathlib import Path\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Device:\", device)\n","\n","# PATHS\n","inet_root        = Path(\"./datasets/inet100\")\n","TEST_PT          = inet_root / \"test.pt\"\n","\n","output_inet_root = Path(\"./best_models/output_inet\")\n","enc_save_root    = inet_root / \"encoded_test_latent\"\n","enc_save_root.mkdir(parents=True, exist_ok=True)\n","\n","assert TEST_PT.exists(), f\"Missing: {TEST_PT}\"\n","\n","inet_model_cfgs = {\n","    \"AuE\": {\n","        \"dir\":  output_inet_root / \"output_inet_ae\",\n","        \"ckpt\": \"best_overall_AuE.pt\",\n","    },\n","    \"VAE\": {\n","        \"dir\":  output_inet_root / \"output_inet_vae\",\n","        \"ckpt\": \"best_overall_VAE.pt\",\n","    },\n","    \"VQVE\": {\n","        \"dir\":  output_inet_root / \"output_inet_vqvae\",\n","        \"ckpt\": \"best_overall_VQVE.pt\",\n","    },\n","    \"VQVA2\": {\n","        \"dir\":  output_inet_root / \"output_inet_vqvae2\",\n","        \"ckpt\": \"best_overall_VQVA2.pt\",\n","    },\n","}\n","\n","Xte = torch.load(TEST_PT, map_location=\"cpu\", weights_only=True)\n","print(\"Xte:\", tuple(Xte.shape), Xte.dtype, \"range\", (float(Xte.min()), float(Xte.max())))\n","\n","test_ds = TensorDataset(Xte)\n","test_loader = DataLoader(test_ds, batch_size=256, shuffle=False)\n","\n","# MODELS\n","class Snake(nn.Module):\n","    def __init__(self, alpha=1.0):\n","        super().__init__()\n","        self.alpha = nn.Parameter(torch.tensor(alpha))\n","    def forward(self, x):\n","        a = self.alpha.abs() + 1e-6\n","        return x + (1.0 / a) * torch.sin(a * x).pow(2)\n","\n","BOTTLENECK_CH = 56\n","CODEBOOK_SIZE = 512\n","COMMIT_BETA   = 0.25\n","TOP_CH        = 56\n","\n","class AuE(nn.Module):\n","    def __init__(self, ch=BOTTLENECK_CH):\n","        super().__init__()\n","        self.enc = nn.Sequential(\n","            nn.Conv2d(1, 32, 3, padding=1), Snake(),\n","            nn.Conv2d(32, 64, 4, stride=2, padding=1), Snake(),\n","            nn.Conv2d(64, ch, 4, stride=2, padding=1), Snake()\n","        )\n","        self.dec = nn.Sequential(\n","            nn.ConvTranspose2d(ch, 64, 2, stride=2), Snake(),\n","            nn.ConvTranspose2d(64, 32, 2, stride=2), Snake(),\n","            nn.Conv2d(32, 1, 1), nn.Tanh()\n","        )\n","    def forward(self, x):\n","        z = self.enc(x)\n","        xh = self.dec(z)\n","        return xh, {}\n","\n","class VAE(nn.Module):\n","    def __init__(self, ch=BOTTLENECK_CH):\n","        super().__init__()\n","        self.enc = nn.Sequential(\n","            nn.Conv2d(1, 32, 3, padding=1), Snake(),\n","            nn.Conv2d(32, 64, 4, stride=2, padding=1), Snake()\n","        )\n","        self.mu     = nn.Conv2d(64, ch, 3, padding=1)\n","        self.logvar = nn.Conv2d(64, ch, 3, padding=1)\n","        self.dec = nn.Sequential(\n","            nn.ConvTranspose2d(ch, 64, 2, stride=2), Snake(),\n","            nn.Conv2d(64, 32, 3, padding=1), Snake(),\n","            nn.Conv2d(32, 1, 1), nn.Tanh()\n","        )\n","\n","    def reparam(self, mu, logv):\n","        std = (0.5 * logv).exp()\n","        eps = torch.randn_like(std)\n","        return mu + eps * std\n","\n","    def forward(self, x):\n","        h  = self.enc(x)\n","        mu = self.mu(h)\n","        lv = self.logvar(h)\n","        z  = self.reparam(mu, lv) if self.training else mu\n","        xh = self.dec(z)\n","        kld = (-0.5 * (1 + lv - mu.pow(2) - lv.exp())).mean()\n","        return xh, {\"kld\": kld, \"mu\": mu, \"logvar\": lv}\n","\n","class VectorQuantizer(nn.Module):\n","    def __init__(self, K, D, beta=COMMIT_BETA):\n","        super().__init__()\n","        self.K, self.D, self.beta = K, D, beta\n","        self.emb = nn.Embedding(K, D)\n","        self.emb.weight.data.uniform_(-1.0 / D, 1.0 / D)\n","    def forward(self, z):\n","        zf   = z.permute(0, 2, 3, 1).contiguous()\n","        flat = zf.view(-1, self.D)\n","        dist = (flat.pow(2).sum(1, keepdim=True)\n","                - 2 * flat @ self.emb.weight.t()\n","                + self.emb.weight.pow(2).sum(1))\n","        ind  = dist.argmin(1)\n","        zq   = self.emb(ind).view_as(zf)\n","\n","        commit = self.beta * ((zq - zf.detach())**2).mean()\n","        codebk = ((zf - zq.detach())**2).mean()\n","        loss = commit + codebk\n","\n","        zq = zf + (zq - zf).detach()\n","        return zq.permute(0, 3, 1, 2).contiguous(), loss\n","\n","class VQVE(nn.Module):\n","    def __init__(self, ch=BOTTLENECK_CH, K=CODEBOOK_SIZE, beta=COMMIT_BETA):\n","        super().__init__()\n","        self.enc = nn.Sequential(\n","            nn.Conv2d(1, 32, 4, stride=2, padding=1), Snake(),\n","            nn.Conv2d(32, ch, 4, stride=2, padding=1), Snake(),\n","        )\n","        self.vq  = VectorQuantizer(K, ch, beta)\n","        self.dec = nn.Sequential(\n","            nn.ConvTranspose2d(ch, 32, 4, stride=2, padding=1), Snake(),\n","            nn.ConvTranspose2d(32, 1, 4, stride=2, padding=1), Snake(),\n","            nn.Tanh()\n","        )\n","    def forward(self, x):\n","        z = self.enc(x)\n","        zq, lvq = self.vq(z)\n","        xh = self.dec(zq)\n","        return xh, {\"vq\": lvq}\n","\n","class VQVA2(nn.Module):\n","    def __init__(self, ch=BOTTLENECK_CH, top_ch=TOP_CH, K=CODEBOOK_SIZE, beta=COMMIT_BETA):\n","        super().__init__()\n","        self.enc_b = nn.Sequential(\n","            nn.Conv2d(1, 32, 4, stride=2, padding=1), Snake(),\n","            nn.Conv2d(32, ch, 4, stride=2, padding=1), Snake()\n","        )\n","        self.enc_t = nn.Sequential(\n","            nn.Conv2d(ch, top_ch, 4, stride=2, padding=1), Snake()\n","        )\n","        self.vq_t = VectorQuantizer(K, top_ch, beta)\n","        self.vq_b = VectorQuantizer(K, ch, beta)\n","\n","        self.up_t = nn.Sequential(\n","            nn.ConvTranspose2d(top_ch, ch, 4, stride=2, padding=1), Snake(),\n","            nn.Conv2d(ch, ch, 3, padding=1), Snake()\n","        )\n","        self.dec = nn.Sequential(\n","            nn.ConvTranspose2d(ch * 2, 64, 4, stride=2, padding=1), Snake(),\n","            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1), Snake(),\n","            nn.Conv2d(32, 1, 1), Snake(),\n","            nn.Tanh()\n","        )\n","    def forward(self, x):\n","        zb = self.enc_b(x)\n","        zt = self.enc_t(zb)\n","        zqt, lt = self.vq_t(zt)\n","        up = self.up_t(zqt)\n","\n","        Hb, Wb = zb.shape[-2:]\n","        if up.shape[-2] < Hb or up.shape[-1] < Wb:\n","            up = F.pad(up, (0, max(0, Wb-up.shape[-1]), 0, max(0, Hb-up.shape[-2])))\n","        up = up[:, :, :Hb, :Wb]\n","\n","        zb_input = zb + up\n","        zqb, lb = self.vq_b(zb_input)\n","\n","        xh = self.dec(torch.cat([zqb, up], dim=1))\n","        return xh, {\"vq_top\": lt, \"vq_bottom\": lb}\n","\n","def build_model_by_name(name: str) -> nn.Module:\n","    if name == \"AuE\":   return AuE()\n","    if name == \"VAE\":   return VAE()\n","    if name == \"VQVE\":  return VQVE()\n","    if name == \"VQVA2\": return VQVA2()\n","    raise ValueError(f\"Unknown model: {name}\")\n","\n","def load_best_inet_model_for_encoding(model_name: str) -> nn.Module:\n","    info = inet_model_cfgs[model_name]\n","    ckpt_path = info[\"dir\"] / info[\"ckpt\"]\n","    assert ckpt_path.exists(), f\"Checkpoint not found: {ckpt_path}\"\n","\n","    state = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)\n","    sd = state[\"model_state\"] if (isinstance(state, dict) and \"model_state\" in state) else state\n","\n","    model = build_model_by_name(model_name)\n","    model.load_state_dict(sd, strict=False)\n","    model.to(device).eval()\n","    return model\n","\n","@torch.no_grad()\n","def encode_batch(model_name: str, model: nn.Module, xb: torch.Tensor) -> torch.Tensor:\n","    xb = xb.to(device)\n","    if model_name == \"AuE\":\n","        return model.enc(xb).cpu()\n","    if model_name == \"VAE\":\n","        h = model.enc(xb)\n","        return model.mu(h).cpu()\n","    if model_name == \"VQVE\":\n","        return model.enc(xb).cpu()\n","    if model_name == \"VQVA2\":\n","        zb = model.enc_b(xb)\n","        zt = model.enc_t(zb)\n","        zt_up = F.interpolate(zt, size=zb.shape[-2:], mode=\"nearest\")\n","        return torch.cat([zb, zt_up], dim=1).cpu()\n","    raise ValueError(model_name)\n","\n","# ENCODE FULL TEST SET + SAVE\n","all_latent_paths = {}\n","\n","for name in [\"AuE\", \"VAE\", \"VQVE\", \"VQVA2\"]:\n","    ckpt_path = inet_model_cfgs[name][\"dir\"] / inet_model_cfgs[name][\"ckpt\"]\n","    if not ckpt_path.exists():\n","        print(f\"\\n=== Skipping {name} (missing: {ckpt_path}) ===\")\n","        continue\n","\n","    print(f\"\\n=== Encoding inet100 test set – {name} ===\")\n","    model = load_best_inet_model_for_encoding(name)\n","\n","    latents = []\n","    for (xb,) in test_loader:\n","        xb = xb.float()\n","        z = encode_batch(name, model, xb)\n","        latents.append(z)\n","\n","    Z = torch.cat(latents, dim=0).numpy()\n","\n","    out_path = enc_save_root / f\"inet100_{name}_test_latent.npy\"\n","    np.save(out_path, Z)\n","    all_latent_paths[name] = str(out_path)\n","\n","    print(f\"  Saved {name} latents: {Z.shape} -> {out_path}\")\n","\n","print(\"\\nAll encoded test latents saved:\")\n","for k, v in all_latent_paths.items():\n","    print(f\"  {k}: {v}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1fxjtilGzepI","executionInfo":{"status":"ok","timestamp":1765782419922,"user_tz":360,"elapsed":9751,"user":{"displayName":"Swati Shahi","userId":"11305998299635410874"}},"outputId":"676c3d72-9f78-44b0-a501-da5c4521eb22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n","Xte: (5000, 1, 28, 28) torch.float16 range (-1.0, 1.0)\n","\n","=== Encoding inet100 test set – AuE ===\n","  Saved AuE latents: (5000, 56, 7, 7) -> datasets/inet100/encoded_test_latent/inet100_AuE_test_latent.npy\n","\n","=== Encoding inet100 test set – VAE ===\n","  Saved VAE latents: (5000, 56, 14, 14) -> datasets/inet100/encoded_test_latent/inet100_VAE_test_latent.npy\n","\n","=== Encoding inet100 test set – VQVE ===\n","  Saved VQVE latents: (5000, 56, 7, 7) -> datasets/inet100/encoded_test_latent/inet100_VQVE_test_latent.npy\n","\n","=== Encoding inet100 test set – VQVA2 ===\n","  Saved VQVA2 latents: (5000, 112, 7, 7) -> datasets/inet100/encoded_test_latent/inet100_VQVA2_test_latent.npy\n","\n","All encoded test latents saved:\n","  AuE: datasets/inet100/encoded_test_latent/inet100_AuE_test_latent.npy\n","  VAE: datasets/inet100/encoded_test_latent/inet100_VAE_test_latent.npy\n","  VQVE: datasets/inet100/encoded_test_latent/inet100_VQVE_test_latent.npy\n","  VQVA2: datasets/inet100/encoded_test_latent/inet100_VQVA2_test_latent.npy\n"]}]},{"cell_type":"code","source":["# Create Input train & test in numpy format\n","from pathlib import Path\n","import torch\n","import numpy as np\n","\n","# PATHS\n","ROOT = Path(\".\")\n","INET_ROOT = ROOT / \"datasets/inet100\"\n","\n","TRAIN_PT = INET_ROOT / \"train.pt\"\n","TEST_PT  = INET_ROOT / \"test.pt\"\n","\n","TRAIN_OUT_DIR = INET_ROOT / \".\"\n","TEST_OUT_DIR  = INET_ROOT / \".\"\n","TRAIN_OUT_DIR.mkdir(parents=True, exist_ok=True)\n","TEST_OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","TRAIN_NPY = TRAIN_OUT_DIR / \"inet100_train.npy\"\n","TEST_NPY  = TEST_OUT_DIR  / \"inet100_test.npy\"\n","\n","print(\"Loading ImageNet100 cached tensors...\")\n","\n","X_train = torch.load(TRAIN_PT, map_location=\"cpu\", weights_only=True)\n","X_test  = torch.load(TEST_PT,  map_location=\"cpu\", weights_only=True)\n","\n","print(\"Loaded:\")\n","print(\"  train:\", X_train.shape, X_train.dtype)\n","print(\"  test :\", X_test.shape,  X_test.dtype)\n","\n","assert X_train.ndim == 4 and X_train.shape[1] == 1, \"Expected (N,1,28,28)\"\n","assert X_test.ndim  == 4 and X_test.shape[1]  == 1, \"Expected (N,1,28,28)\"\n","\n","# Use float32 for NumPy interoperability\n","train_np = X_train.float().numpy()\n","test_np  = X_test.float().numpy()\n","\n","print(\"Converted to NumPy:\")\n","print(\"  train:\", train_np.shape, train_np.dtype,\n","      \"range:\", (train_np.min(), train_np.max()))\n","print(\"  test :\", test_np.shape,  test_np.dtype,\n","      \"range:\", (test_np.min(),  test_np.max()))\n","\n","np.save(TRAIN_NPY, train_np)\n","np.save(TEST_NPY,  test_np)\n","\n","print(\"\\nSaved:\")\n","print(\" \", TRAIN_NPY.resolve())\n","print(\" \", TEST_NPY.resolve())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XfBcIDfYaslT","executionInfo":{"status":"ok","timestamp":1765782855029,"user_tz":360,"elapsed":8835,"user":{"displayName":"Swati Shahi","userId":"11305998299635410874"}},"outputId":"5d8af094-819b-4f3a-a9d2-98fd52d7e8f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading ImageNet100 cached tensors...\n","Loaded:\n","  train: torch.Size([130000, 1, 28, 28]) torch.float16\n","  test : torch.Size([5000, 1, 28, 28]) torch.float16\n","Converted to NumPy:\n","  train: (130000, 1, 28, 28) float32 range: (np.float32(-1.0), np.float32(1.0))\n","  test : (5000, 1, 28, 28) float32 range: (np.float32(-1.0), np.float32(1.0))\n","\n","Saved:\n","  /content/gdrive/.shortcut-targets-by-id/1UMow24kXYpDLYgShcir7-CB3ZYQsgEih/Colab Notebooks/autoencoders/datasets/inet100/inet100_train.npy\n","  /content/gdrive/.shortcut-targets-by-id/1UMow24kXYpDLYgShcir7-CB3ZYQsgEih/Colab Notebooks/autoencoders/datasets/inet100/inet100_test.npy\n"]}]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}